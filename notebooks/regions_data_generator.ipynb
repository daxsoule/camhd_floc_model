{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regions\n",
    "Import regions data from [CamHD_motion_metadata](https://github.com/CamHD-Analysis/CamHD_motion_metadata) into a Pandas dataframe. The region_list.txt file was generated usng the following BASH command from inside the CamHD_motion_metadata directory:\n",
    "```bash\n",
    "find $PWD -type f -name \"*optical_flow_regions.json\" | grep --color=never -i region | sort > ~/camhd_floc_model/data_camhd/region_list_generated.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a Dask cluster\n",
    "We do this first because it can take a while for the Kubernetes cluster to scale up to accomodate workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through JSON files and create lists with info for the desired scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframe from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "filename = []\n",
    "scene_tag = []\n",
    "deployment = []\n",
    "start_frame = []\n",
    "end_frame = []\n",
    "\n",
    "with open('/home/jovyan/camhd_floc_model/data_camhd/region_list_generated.txt') as f:\n",
    "    for line in f:\n",
    "        with open(line.strip()) as l:\n",
    "            data = json.load(l)\n",
    "            for region in data['regions']:\n",
    "                if region['type'] == 'static':\n",
    "                    try:\n",
    "                        if '_p2_z0' in region['sceneTag']:\n",
    "                            url.append('https://rawdata.oceanobservatories.org/files' + data['movie']['URL'])\n",
    "                            filename.append((data['movie']['URL'].split('/')[-1]))\n",
    "                            scene_tag.append(region['sceneTag'])\n",
    "                            deployment.append(int(scene_tag[-1].split('_')[0][1]))                            \n",
    "                            start_frame.append(int(region['startFrame']))\n",
    "                            end_frame.append(int(region['endFrame']))\n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_windows = pd.DataFrame({'filename': filename, 'url': url, 'scene_tag': scene_tag, 'deployment': deployment, 'start_frame': start_frame, 'end_frame': end_frame})\n",
    "scene_windows.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a cell that starts by defining a proper buffer for our start and end frames. The idea being that the buffer will provent us from pulling frames that may include the end or beggining of the CamHD's movement.\n",
    "We go on to create a dataframe of relevent information from a list of movies that fit specifications made in the cell above\n",
    "From here we apply a function to the rows of the dataframe that takes the defined frame_interval for the range give by the start_frame to end_frame\n",
    "We then add that the list of frames as a column 'window' to our data\n",
    "We then go through our dataframe and filter it to display only the rows from the given deployment (5) and pipe this into a new dataframe to work from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of frames to process for each scene window\n",
    " ##### A large frame interval >80 will speed up the processing\n",
    " ##### A small frame interval <25 will provide a high resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_interval = 69\n",
    "window_buffer = 30\n",
    "frame_lists = []\n",
    "for i, start_frame in enumerate(scene_windows.start_frame):\n",
    "    frame_lists.append(list(range(start_frame+window_buffer, scene_windows.end_frame[i]-window_buffer, frame_interval)))\n",
    "scene_windows['frame_list'] = frame_lists\n",
    "scene_windows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrappers to deal with potential get_moov_atom and get_frame timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycamhd as camhd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moov_atom_timeout(filename):\n",
    "    try:\n",
    "        return camhd.get_moov_atom(filename)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_timeout(filename, frame_number, pix_fmt, moov_atom):\n",
    "    if moov_atom:\n",
    "        try:\n",
    "            return camhd.get_frame(filename, frame_number, pix_fmt, moov_atom)\n",
    "        except:\n",
    "            return np.zeros((1080, 1920), dtype=np.uint16)\n",
    "    else:\n",
    "        return np.zeros((1080, 1920), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a Dask array of delayed images\n",
    "In this notebook we don't actually use this Dask array of delayed objects for the analysis. Below we refactor into using a list of delayed functions which I think works better here. Or at least it is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import dask.array as dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_frame_list = []\n",
    "for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "    filename = row.url\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in row.frame_list:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_list.append(dsa.from_delayed(delayed_frame, (1080, 1920), np.uint16))\n",
    "delayed_frame_array = dsa.stack(delayed_frame_list)\n",
    "delayed_frame_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dask array is in many ways like a numpy array, except in this case it holds a set of instructions for how to acquire each chunk of the array, which makes it easy to farm this array out to workers in the cloud using the [distributed](http://distributed.readthedocs.io/en/latest/#) scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = delayed_frame_array[0].compute()\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth(d1, d2, n):\n",
    "    x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "    d = np.sqrt(xx**2+yy**2)\n",
    "    bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n)))\n",
    "    return bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 20 # low cut wavenumber\n",
    "d2 = 400 # high cut wavenumber\n",
    "n = 4\n",
    "bff = butterworth(d1, d2, n)\n",
    "# plt.rc('figure', figsize=(6, 6))\n",
    "#imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup filtering and thresholding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_filter(frame, d1, d2, n):\n",
    "    if frame.ndim == 3 and frame.shape[0] == 1:\n",
    "        I = np.squeeze(frame[0, 0:1024, 0:1024])\n",
    "    else:\n",
    "        I = frame[0:1024, 0:1024]\n",
    "    bff = butterworth(d1, d2, n)\n",
    "    I_fft = np.fft.fft2(I)\n",
    "    I_fft_shift = np.fft.fftshift(I_fft)\n",
    "    I_fft_shift_filt = I_fft_shift*bff # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt)\n",
    "    I_filt = np.fft.ifft2(I_fft_filt)\n",
    "    return I_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4000; # this is an arbitrary threshold that seems to work\n",
    "def frame_thresh(frame, d1, d2, n, threshold):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    I_thresh = np.array(np.absolute(I_filt)>threshold)\n",
    "    return I_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show example of a thresholded subimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_thresh = frame_thresh(frame, d1, d2, n, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Pixels per Labeled Area\\nblue: %i\\nred: %i\\ngreen: %i\\nblack: %i' % \n",
    "      ((I_labeled==1).sum(), (I_labeled==2).sum(), \n",
    "       (I_labeled==3).sum(),(I_labeled==4).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup labeling stats function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a thresholded binary image as input\n",
    "def frame_label_stats(I_thresh):\n",
    "    I_labeled = label(I_thresh)\n",
    "    label_stats = []\n",
    "    for i in range(1, I_labeled.max()+1):\n",
    "        label_stats.append((I_labeled==i).sum())\n",
    "    return label_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble a list of Dask delayed functions using our labeling function\n",
    "Here we abandon the delayed Dask array because I am still not sure of what it buys us. It might be worth returning to, but we will use a simple list of nested delayed objects for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_label_stats = []\n",
    "for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "    filename = row.url\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in row.frame_list:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_thresh = delayed(frame_thresh)(delayed_frame, d1, d2, n, threshold)\n",
    "        delayed_label_stats.append(delayed(frame_label_stats)(delayed_frame_thresh))\n",
    "delayed_label_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(delayed_label_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach the distributed client to the cluster\n",
    "Make sure all of the workers are ready to go before attaching and running compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate label stats for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "label_stats = compute(*delayed_label_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "frame_datenum = []\n",
    "frame_datetime = []\n",
    "frame_numbers = []\n",
    "dbcamhd = pd.read_json('/home/jovyan/floc_gsa_2019/dbcamhd.json', orient=\"records\", lines=True)\n",
    "for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "    for frame_number in row.frame_list:\n",
    "        url.append(row.url)\n",
    "        frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == row.url].iloc[0] + frame_number/29.97\n",
    "        frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "        frame_datenum.append(dates.date2num(frame_datetime[-1]))\n",
    "        frame_numbers.append(frame_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count floc particles for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflocs = [len(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nflocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_floc = [sum(i) for i in label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_floc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results = pd.DataFrame({'url': url, 'frame_number': frame_numbers, 'timestamp': frame_datenum,\n",
    "                        'datetime': frame_datetime, 'nflocs': nflocs, 'label_stats': label_stats, 'total_floc' : total_floc,})\n",
    "regions_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save this data as a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_for_dep_5_03.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
